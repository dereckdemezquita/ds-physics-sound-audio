<html>

<head>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
<title>Cell blab</title>
</head>

<body>
<h1>Description</h1>
<p>
	Make a game, you’re cell, chat room, voices loudness dependant on how far from other cells crowded area.
</p>
<h1>Tech stack</h1>
<ul>
	<li>
		TS
	</li>
	<li>
		Babble; convert modularised code to bundle
	</li>
	<li>
		Express server for testing
	</li>
	<li>
		Webpack for automatically moving the bundle over
	</li>
</ul>
<h1>Notes</h1>
<p>
	Figure out all the math associated and resources, won’t let them chose a bit rate just chose one that sounds good. Check the quality with audacity, we can use different compression method
</p>
<p>
    <strong>Bit rates</strong>: calculating for 500 max cells, they are all talking at once.
</p>
<div class="math-formulas">
	$$
		500 48 kilobit/s / 8 = 3000 kilobytes/s / 1024 = 3MB/s 8; 24 MB/s bandwidth
	$$
</div>
<p>
	Not bad we could potentially do this 1500 people at once with a single VPS.
</p>
<p>
	<strong>Load balancing</strong>: Have a central server, have the website itself, then another place where the audio is being sent to and received from, central server would control which would be used. Nginx has built in support for load balancing so we don't even have to build this.
</p>
<div class="note">
	Domain purchased: www.cellblab.com.
</div>
<h1>Audio processing</h1>
<p>
	<a target="_blank" href="#https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web_Audio_API</a>; we will use this for geting audio from the client.
</p>
<p>
	Note that human hearing ranges from: 20 to 20,000 Hz. The human voice ranges from: "A Female voice frequency range covers fairly upto 350 Hz to 17KHz. Male voice covers a Frequency range of 100Hz to 8KHz."
</p>
<p>
	We will cover from 100 - 8000 Hz, this seems reasonable to get good sound quality.
</p>
<p>
	This doesn't really matter, because what matters is just recording the voice, and cutting out certain frequencies to see what sounds good. Actual testing is required.
</p>
<p>
	Seems that there's not really any good way to manage audio with NodeJS. So we will have to work with raw audio and make our own libraries.
</p>
<p>
	With WebAduioAPI the audio is in pcm format, this is raw and thus lossless. The bit rate is very high. About 705 kbits/s. At around 500 kbits/s we start to see loss in quality. MP3 is at 48 kbits/s. How does MP3 do this?
</p>
<p>
	Seems that they take the lossless audio, and make it lossy; skip some bits in the file to "compress" it. This is exploiting human hearing. Humans can't really notice this loss. We'll have to baisically make our own audio codecs (a device or computer program capable of encoding or decoding a digital data stream <a target="_blank" href="https://en.wikipedia.org/wiki/Audio_codec">Audio_codec</a>).
</p>
<p>
	Using npm module to be able to play raw pcm through speakers, but it does not support 32 bit. Audacity can export 16 bit. Now we'll take this raw audio and remove bits to try and reduce the size; if we can figure this out we can make our own live codec. Take raw data from client microphone and live skip some bits to reduce the size. Then stream this "raw-" to a server, which will create a composite audio for the game.
</p>
<p>
	Analog audio is a wavelength of changing frequency. When we want to record it digitally we sample it every n seconds. 44.1 kHz, this means in 1 second we take 44.1 thousand samples. A sample is a frequency taken at t point in time.
</p>
<p>
	Bit depth is like the resolution of the sample. A common one is 16 bit depth, it goes up to about 32 bit depth. 24 bit is for audiophiles who think they can hear the difference. What it is, is how many bits we use to encode the sample, so we take x amount of samples from analogue this makes a digital audio. Now we have each of these samples encoded at a certain resolution; bit depth.
</p>
<p>
	Finally the whole is played back at a certain rate. This is:
</p>
<div class="mathsFormulas">
	$$
		Bit \, depth \times frequency \, kHz
	$$
	$$
		16 \times 44.1 = 705.6 kbps \, (bit rate)
	$$
</div>
<p>
	What the audio actually looks like is just a giant array of numbers. That's it. Floating points, or integers. Floating points are called normalised, because they are from -1 to 1. 
</p>
<p>
	Still worried about cpu usage when calculating multiple streams to one composition. But I think should be ok. At worst maybe have just that part be done with C++ for efficiency? Maybe averaging out would be an ok way to combine audios into composite audio.
</p>
<p>
	<strong>Bit depth</strong>: sample size. How many bits you use in encoding the frequency.

</p>
<p>
	<strong>Sample rate</strong>: the rate at which you record a sample of audio frequency.

</p>
<p>
	<strong>Bit rate</strong>: how many bits of data are used per time unit to encode data at given sample rate and bit depth. Generally bits/kbits/mbits per second.
</p>
<p>
	If the frequency of a sample doesn't perfectly match a number in that range, closest is selected. Thus, higher bit depth = better audio.
</p>
<p>
	If we have 16 bit bit depth, and we want to record up to 20 kHz, 1 - 20 000 Hz, so we would map the range 1 - 65535 (arbitrary value range) to the range of 1 - 20 k. When we record a frequency say 5 Hz, we map that to the range and chose the closest value. The higher the frequency range the less accurate it gets.
</p>
<p>
	This seems to be what Mp3 does. Another tecnique that Mp3 uses is Huffman encoding, what it does is it finds the most common numbers, and assigns them a short binary number. This thus reduces the total bit size.
</p>
<p>
	We tested a lowpass filter to 8000 Hz, this still sounded ok. It's cutting out a good half of the normal frequencies. However, not half half, as we talk not all frequencies are found outside this 0 - 8 k range.
</p>
<p>
	Huffman encoding will be useful for live audio. This will help the most. We could use machine learning for this. Convert to 16 pcm, then analyse which numbers occur most frequently.
</p>
<a target="_blank" href="./data/signed-16bit-pcm-44-1khz.raw">signed-16bit-pcm-44-1khz.raw</a>
<p>
	This audio file is at signed 16 bit pcm, going to open it and see what inside. NodeJS can convert this the 16 bit numbers. fs readfilesync and read the file by default NodeJS will make it into a buffer. So if we want the raw numbers we will have to convert the uint_8 array into a uint_16 array.
</p>
<p>
	If we look at it as an array of 8 bit integers, every 2 bytes will be one sample. Problem is we don't know what order it goes in.
</p>
<p>
	If I can get each user's audio stream to an average of 64kbps, that's 64Mbps of bandwidth if 1000 people were talking at once. Not bad. At this rate, we'll probably allow better audio.
</p>
<p>
	<strong>Byte Order</strong>: "When more than one byte is used to represent a PCM sample, the byte order (big endian vs. little endian) must be known. Due to the widespread use of little-endian Intel CPUs, little-endian PCM tends to be the most common byte orientation."
</p>
<h2>Audio anlaysis</h2>

<h3>Document set up</h3>
<!--begin.rcode install-packages, eval = FALSE
install.packages("devtools")
install.packages("av")
devtools::install_github("dereckdemezquita/octavius", force = TRUE)
end.rcode-->

<!--begin.rcode libraries-packages
library("devtools")
library("av")
library("octavius")
end.rcode-->

<!--begin.rcode output-params, include = FALSE, echo = FALSE
par(mfrow = c(1, 1)); # Reseting margins on plots

knitr::opts_chunk$set(echo = TRUE, results = "hide", message = FALSE, warning = FALSE);
end.rcode-->

<!--begin.rcode
wd <- getFileWd()
setwd(wd)
end.rcode-->

<p>
	We can easily handle Mp3 audio with the av package. Seen below, here we just visualise the data.
</p>

<!--begin.rcode mp3-3400lowpass-pcm, results = "show"
mp3 <- "data/lowpass3400khz-64kpbs-441khz.mp3"
av::av_media_info(mp3)

pcm_data <- read_audio_bin(mp3, channels = 1)
plot(pcm_data, type = 'l')

summary(pcm_data)
end.rcode-->

<!--begin.rcode mp3-3400lowpass-fft
fft_data <- read_audio_fft(mp3)
dim(fft_data)

plot(fft_data)
end.rcode-->

<p>
	Figuring out the information needed for doing Huffman coding.
</p>
<!--begin.rcode
file <- "data/signed-16bit-pcm-44-1khz.raw"
raw <- read_file_raw(file)
raw <- readBin(file, "raw", n = 300000)

strtoi(raw, base = 16L)

binary <- R.utils::intToBin(strtoi(raw, base = 16L))
end.rcode-->

<footer>
	<ul>
		<li>
			https://wiki.multimedia.cx/index.php/PCM
		</li>
	</ul>
</footer>
</body>
</html>
